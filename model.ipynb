{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images and annotations\n",
    "def load_data(image_folder, annotation_folder):\n",
    "    image_files = os.listdir(image_folder)\n",
    "    images = []\n",
    "    annotations = []\n",
    "    \n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(image_folder, img_file)\n",
    "        annotation_path = os.path.join(annotation_folder, img_file.replace('.jpg', '.xml'))\n",
    "        \n",
    "        # Load image\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (224, 224))  # Resize image to 224x224\n",
    "        images.append(img)\n",
    "        \n",
    "        # Load XML annotation\n",
    "        tree = ET.parse(annotation_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Extract polygon points\n",
    "        points = []\n",
    "        for pt in root.findall('.//pt'):\n",
    "            x = int(pt.find('x').text)\n",
    "            y = int(pt.find('y').text)\n",
    "            points.append((x, y))\n",
    "        annotations.append(points)\n",
    "    \n",
    "    return np.array(images), annotations\n",
    "\n",
    "# Load data\n",
    "image_folder = 'Annonated_Shapes'\n",
    "annotation_folder = 'Annonated_XML'\n",
    "images, annotations = load_data(image_folder, annotation_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert annotations to binary edge images\n",
    "def annotations_to_edges(annotations, image_shape):\n",
    "    edge_images = []\n",
    "    for annotation in annotations:\n",
    "        edge_img = np.zeros(image_shape[:2], dtype=np.uint8)\n",
    "        for i in range(len(annotation)):\n",
    "            cv2.line(edge_img, annotation[i], annotation[(i+1)%len(annotation)], 255, 1)\n",
    "        edge_images.append(edge_img)\n",
    "    return np.array(edge_images)\n",
    "\n",
    "edge_images = annotations_to_edges(annotations, images[0].shape)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_images, val_images, train_edges, val_edges = train_test_split(images, edge_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize images\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "val_images = val_images.astype('float32') / 255.0\n",
    "train_edges = train_edges.astype('float32') / 255.0\n",
    "val_edges = val_edges.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 111, 111, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 54, 54, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 346112)            0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               44302464  \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50176)             6472704   \n",
      "                                                                 \n",
      " reshape_6 (Reshape)         (None, 224, 224)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,868,416\n",
      "Trainable params: 50,868,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(input_shape[0] * input_shape[1], activation='sigmoid'),  # Assuming flat output for edge image\n",
    "        layers.Reshape((input_shape[0], input_shape[1]))\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "model = build_model(input_shape)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0747 - accuracy: 0.2760 - val_loss: 0.0788 - val_accuracy: 0.3296\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0749 - accuracy: 0.3643 - val_loss: 0.0794 - val_accuracy: 0.3550\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0753 - accuracy: 0.3757 - val_loss: 0.0800 - val_accuracy: 0.3580\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0759 - accuracy: 0.3788 - val_loss: 0.0806 - val_accuracy: 0.3591\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0760 - accuracy: 0.3802 - val_loss: 0.0806 - val_accuracy: 0.3598\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0760 - accuracy: 0.3806 - val_loss: 0.0806 - val_accuracy: 0.3598\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0760 - accuracy: 0.3806 - val_loss: 0.0806 - val_accuracy: 0.3599\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0760 - accuracy: 0.3806 - val_loss: 0.0806 - val_accuracy: 0.3599\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0760 - accuracy: 0.3806 - val_loss: 0.0806 - val_accuracy: 0.3599\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0760 - accuracy: 0.3806 - val_loss: 0.0806 - val_accuracy: 0.3599\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0760 - accuracy: 0.3806 - val_loss: 0.0806 - val_accuracy: 0.3599\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0760 - accuracy: 0.3806 - val_loss: 0.0806 - val_accuracy: 0.3599\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0760 - accuracy: 0.3806 - val_loss: 0.0806 - val_accuracy: 0.3599\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0760 - accuracy: 0.3806 - val_loss: 0.0806 - val_accuracy: 0.3599\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0760 - accuracy: 0.3806 - val_loss: 0.0806 - val_accuracy: 0.3599\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0760 - accuracy: 0.3806 - val_loss: 0.0806 - val_accuracy: 0.3599\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0760 - accuracy: 0.3806 - val_loss: 0.0806 - val_accuracy: 0.3599\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 43s 3s/step - loss: 0.0760 - accuracy: 0.3806 - val_loss: 0.0806 - val_accuracy: 0.3599\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.0760 - accuracy: 0.3806 - val_loss: 0.0806 - val_accuracy: 0.3599\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 43s 3s/step - loss: 0.0760 - accuracy: 0.3806 - val_loss: 0.0806 - val_accuracy: 0.3599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd010661f0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Training\n",
    "\n",
    "model.fit(train_images, train_edges, epochs=20, batch_size=32, validation_data=(val_images, val_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# 4. Inference\n",
    "\n",
    "def annotate_edge(image_path, model):\n",
    "    # Load test image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img_norm = img.astype('float32') / 255.0\n",
    "    img_norm = np.expand_dims(img_norm, axis=0)\n",
    "    \n",
    "    # Predict edge map\n",
    "    edge_map = model.predict(img_norm)[0]\n",
    "    edge_map = (edge_map > 0.5).astype(np.uint8) * 255\n",
    "    \n",
    "    # Convert edge map to XML annotation\n",
    "    edge_points = np.column_stack(np.where(edge_map > 0))\n",
    "    \n",
    "    root = ET.Element(\"annotation\")\n",
    "    filename = ET.SubElement(root, \"filename\")\n",
    "    filename.text = os.path.basename(image_path)\n",
    "    \n",
    "    obj = ET.SubElement(root, \"object\")\n",
    "    name = ET.SubElement(obj, \"name\")\n",
    "    name.text = \"shape\"\n",
    "    \n",
    "    polygon = ET.SubElement(obj, \"polygon\")\n",
    "    for point in edge_points:\n",
    "        pt = ET.SubElement(polygon, \"pt\")\n",
    "        x = ET.SubElement(pt, \"x\")\n",
    "        x.text = str(point[1])\n",
    "        y = ET.SubElement(pt, \"y\")\n",
    "        y.text = str(point[0])\n",
    "    \n",
    "    tree = ET.ElementTree(root)\n",
    "    xml_path = image_path.replace('.jpg', '_annotated.xml')\n",
    "    tree.write(xml_path)\n",
    "    \n",
    "    # Save annotated image\n",
    "    contours, _ = cv2.findContours(edge_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(img, contours, -1, (0, 255, 0), 2)\n",
    "    annotated_img_path = image_path.replace('.jpg', '_annotated.jpg')\n",
    "    cv2.imwrite(annotated_img_path, img)\n",
    "\n",
    "# Test annotation on a sample image\n",
    "test_image_path = 'img8.jpg'\n",
    "annotate_edge(test_image_path, model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
